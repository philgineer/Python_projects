{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타이타닉 생존자 예측\n",
    "https://www.kaggle.com/c/2019-1st-ml-month-with-kakr/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan A\n",
    "- supervised learning\n",
    "- decision tree, random forest, XG boost\n",
    "- classification (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan B\n",
    "- supervised learning\n",
    "- multi layer regression\n",
    "- classification (0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- survival - 생존유무, target 값. (0 = 사망, 1 = 생존)\n",
    "- pclass - 티켓 클래스. (1 = 1st, 2 = 2nd, 3 = 3rd)\n",
    "- sex - 성별\n",
    "- Age - 나이(세)\n",
    "- sibsp - 함께 탑승한 형제자매, 배우자 수 총합\n",
    "- parch - 함께 탑승한 부모, 자녀 수 총합\n",
    "- ticket - 티켓 넘버\n",
    "- fare - 탑승 요금\n",
    "- cabin - 객실 넘버\n",
    "- embarked - 탑승 항구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\frame.py:7116: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>0</td>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A.5. 3236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>39.0</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>0</td>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC 17758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>38.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>0</td>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>0</td>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>1</td>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Cabin Embarked      Fare                          Name  Parch  \\\n",
       "1304   NaN   NaN        S    8.0500            Spector, Mr. Woolf      0   \n",
       "1305  39.0  C105        C  108.9000  Oliva y Ocana, Dona. Fermina      0   \n",
       "1306  38.5   NaN        S    7.2500  Saether, Mr. Simon Sivertsen      0   \n",
       "1307   NaN   NaN        S    8.0500           Ware, Mr. Frederick      0   \n",
       "1308   NaN   NaN        C   22.3583      Peter, Master. Michael J      1   \n",
       "\n",
       "      PassengerId  Pclass     Sex  SibSp  Survived              Ticket  \n",
       "1304         1305       3    male      0       NaN           A.5. 3236  \n",
       "1305         1306       1  female      0       NaN            PC 17758  \n",
       "1306         1307       3    male      0       NaN  SOTON/O.Q. 3101262  \n",
       "1307         1308       3    male      0       NaN              359309  \n",
       "1308         1309       3    male      1       NaN                2668  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.append(data2, ignore_index=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1046.000</td>\n",
       "      <td>1308.000</td>\n",
       "      <td>1309.000</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>1309.000</td>\n",
       "      <td>1309.000</td>\n",
       "      <td>891.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.881</td>\n",
       "      <td>33.295</td>\n",
       "      <td>0.385</td>\n",
       "      <td>655.00</td>\n",
       "      <td>2.295</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.413</td>\n",
       "      <td>51.759</td>\n",
       "      <td>0.866</td>\n",
       "      <td>378.02</td>\n",
       "      <td>0.838</td>\n",
       "      <td>1.042</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000</td>\n",
       "      <td>7.896</td>\n",
       "      <td>0.000</td>\n",
       "      <td>328.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000</td>\n",
       "      <td>14.454</td>\n",
       "      <td>0.000</td>\n",
       "      <td>655.00</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.000</td>\n",
       "      <td>31.275</td>\n",
       "      <td>0.000</td>\n",
       "      <td>982.00</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000</td>\n",
       "      <td>512.329</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>3.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age      Fare     Parch  PassengerId    Pclass     SibSp  Survived\n",
       "count  1046.000  1308.000  1309.000      1309.00  1309.000  1309.000   891.000\n",
       "mean     29.881    33.295     0.385       655.00     2.295     0.499     0.384\n",
       "std      14.413    51.759     0.866       378.02     0.838     1.042     0.487\n",
       "min       0.170     0.000     0.000         1.00     1.000     0.000     0.000\n",
       "25%      21.000     7.896     0.000       328.00     2.000     0.000     0.000\n",
       "50%      28.000    14.454     0.000       655.00     3.000     0.000     0.000\n",
       "75%      39.000    31.275     0.000       982.00     3.000     1.000     1.000\n",
       "max      80.000   512.329     9.000      1309.00     3.000     8.000     1.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(data.describe(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 122.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리 1: age, cabin, embarked에 null 값 존재 -> 결측치 제거, name drop\n",
    "- Cabin은 결측치가 너무 많으므로 아예 drop\n",
    "- Embarked, Age는 mean과 median 두 경우로 결측치 대체해볼 것. (데이터가 891개밖에 안되어 행 제거하면 안될듯..): copy, copy2\n",
    "\n",
    "### 1-a. Copy (Age: NaN <- mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  PassengerId  Pclass     Sex  SibSp  \\\n",
       "0  22.0        S   7.2500      0            1       3    male      1   \n",
       "1  38.0        C  71.2833      0            2       1  female      1   \n",
       "2  26.0        S   7.9250      0            3       3  female      0   \n",
       "3  35.0        S  53.1000      0            4       1  female      1   \n",
       "4  35.0        S   8.0500      0            5       3    male      0   \n",
       "\n",
       "   Survived            Ticket  \n",
       "0       0.0         A/5 21171  \n",
       "1       1.0          PC 17599  \n",
       "2       1.0  STON/O2. 3101282  \n",
       "3       1.0            113803  \n",
       "4       0.0            373450  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy = data.copy()\n",
    "data_copy = data_copy.drop('Cabin', axis=1).drop('Name', axis=1)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       22.0\n",
       "1       38.0\n",
       "2       26.0\n",
       "3       35.0\n",
       "4       35.0\n",
       "        ... \n",
       "1304     NaN\n",
       "1305    39.0\n",
       "1306    38.5\n",
       "1307     NaN\n",
       "1308     NaN\n",
       "Name: Age, Length: 1309, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x21b21a6ce10>,\n",
       "  <matplotlib.lines.Line2D at 0x21b21a83198>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x21b21a834e0>,\n",
       "  <matplotlib.lines.Line2D at 0x21b21a83828>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x21b21a6ccc0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x21b21a83b70>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x21b21a83eb8>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(data_copy.Age[np.isnan(data_copy.Age) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1304     True\n",
       "1305    False\n",
       "1306    False\n",
       "1307     True\n",
       "1308     True\n",
       "Name: Age, Length: 1309, dtype: bool"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data_copy.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1309.000000\n",
       "mean       29.881138\n",
       "std        12.883193\n",
       "min         0.170000\n",
       "25%        22.000000\n",
       "50%        29.881138\n",
       "75%        35.000000\n",
       "max        80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Age[np.isnan(data_copy.Age) == True] = np.mean(data_copy.Age)\n",
    "data_copy.Age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-b. Copy2 (Age: NaN <- median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy2 = data.copy()\n",
    "data_copy2 = data_copy2.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "1304    False\n",
       "1305    False\n",
       "1306    False\n",
       "1307    False\n",
       "1308    False\n",
       "Name: Age, Length: 1309, dtype: bool"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data_copy2.Age == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(data_copy2.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(data_copy2.Age[np.isnan(data_copy2.Age) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1309.000000\n",
       "mean       29.503186\n",
       "std        12.905241\n",
       "min         0.170000\n",
       "25%        22.000000\n",
       "50%        28.000000\n",
       "75%        35.000000\n",
       "max        80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy2.Age[np.isnan(data_copy2.Age) == True] = np.median(data_copy2.Age[np.isnan(data_copy2.Age) == False])\n",
    "data_copy2.Age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전처리2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Age            1309 non-null float64\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      843\n",
       "female    466\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sex -> int\n",
    "data_copy.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    843\n",
       "0    466\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Sex.replace({'female':0, 'male':1}, inplace=True)\n",
    "data_copy.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embarked -> int\n",
    "data_copy.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    914\n",
       "1.0    270\n",
       "2.0    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_copy.Embarked.replace({'S':0, 'C':1, \"Q\":2}, inplace=True)\n",
    "#data_copy.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게 넣으면 순위가 생겨서 안됨!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더미변수로 만들어 줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      C  Q  S\n",
       "0     0  0  1\n",
       "1     1  0  0\n",
       "2     0  0  1\n",
       "3     0  0  1\n",
       "4     0  0  1\n",
       "...  .. .. ..\n",
       "1304  0  0  1\n",
       "1305  1  0  0\n",
       "1306  0  0  1\n",
       "1307  0  0  1\n",
       "1308  1  0  0\n",
       "\n",
       "[1309 rows x 3 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data_copy.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data_copy.Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Age            1309 non-null float64\n",
      "Embarked       1307 non-null float64\n",
      "Fare           1308 non-null float64\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null int64\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1307.000000\n",
       "mean        0.394797\n",
       "std         0.653817\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         2.000000\n",
       "Name: Embarked, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Embarked.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Age            1309 non-null float64\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null int64\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_copy.Embarked[np.isnan(data_copy.Embarked) == True] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1308.000000\n",
       "mean       33.295479\n",
       "std        51.758668\n",
       "min         0.000000\n",
       "25%         7.895800\n",
       "50%        14.454200\n",
       "75%        31.275000\n",
       "max       512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_copy.Fare[np.isnan(data_copy.Fare) == True] = np.mean(data_copy.Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      "Age            1309 non-null float64\n",
      "Embarked       1309 non-null float64\n",
      "Fare           1309 non-null float64\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null int64\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(4), int64(5), object(1)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ticket은 어떻게 할지..?\n",
    "\n",
    "- cluster learning?\n",
    "\n",
    "- 일단 배제하고 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA. 2343        11\n",
       "1601             8\n",
       "CA 2144          8\n",
       "PC 17608         7\n",
       "S.O.C. 14879     7\n",
       "                ..\n",
       "370375           1\n",
       "694              1\n",
       "4135             1\n",
       "32302            1\n",
       "3410             1\n",
       "Name: Ticket, Length: 929, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.Ticket.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.drop(['PassengerId', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D3ABFD0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D3D2F98>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D404390>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D42A908>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D454E80>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D485438>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D4AA9B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D4D2F60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000021B1D4D2F98>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_copy.hist(bins=30, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex        -0.543\n",
       "Pclass     -0.338\n",
       "Age        -0.070\n",
       "SibSp      -0.035\n",
       "Parch       0.082\n",
       "Embarked    0.107\n",
       "Fare        0.257\n",
       "Survived    1.000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_train = data_copy.corr()\n",
    "round(corr_train['Survived'].sort_values(ascending=True), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[(data_copy.Survived == 0) | (data_copy.Survived == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_copy[(data_copy.Survived == 0) | (data_copy.Survived == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[-(data_copy.Survived == 0) & -(data_copy.Survived == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_copy[-(data_copy.Survived == 0) & -(data_copy.Survived == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 평가 패키지\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# data set을 training set / test set 분리 서브 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 의사결정트리 알고리즘 서브 패키지\n",
    "import sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# IPython 내 정보 보여주는 API, raw 데이터가 있는 png jpeg 이미지 객체 만드는 모듈\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import warnings   # warning 메세지 안 보이게 하려고\n",
    "\n",
    "# Operating System과 상호작용하기 위한 기본적 기능(경로 생성, 변경)이 제공되는 모듈\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    549\n",
       "1.0    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target,\n",
    "                                                     test_size=0.3, stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.4417</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3625</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.8500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8417</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.8500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>28.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0458</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Embarked     Fare  Parch  Pclass  Sex  SibSp\n",
       "163  17.000000       0.0   8.6625      0       3    1      0\n",
       "2    26.000000       0.0   7.9250      0       3    0      0\n",
       "182   9.000000       0.0  31.3875      2       3    1      4\n",
       "402  21.000000       0.0   9.8250      0       3    0      1\n",
       "800  34.000000       0.0  13.0000      0       2    1      0\n",
       "..         ...       ...      ...    ...     ...  ...    ...\n",
       "130  33.000000       1.0   7.8958      0       3    1      0\n",
       "653  29.881138       2.0   7.8292      0       3    0      0\n",
       "233   5.000000       0.0  31.3875      2       3    0      4\n",
       "862  48.000000       0.0  25.9292      0       1    0      0\n",
       "744  31.000000       0.0   7.9250      0       3    1      0\n",
       "\n",
       "[623 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0792</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.7125</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.3792</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.4333</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>36.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.7417</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.1375</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>30.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.2667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Embarked     Fare  Parch  Pclass  Sex  SibSp\n",
       "119   2.0       0.0  31.2750      2       3    0      4\n",
       "174  56.0       1.0  30.6958      0       1    1      0\n",
       "683  14.0       0.0  46.9000      2       3    1      5\n",
       "747  30.0       0.0  13.0000      0       2    0      0\n",
       "811  39.0       0.0  24.1500      0       3    1      0\n",
       "..    ...       ...      ...    ...     ...  ...    ...\n",
       "767  30.5       2.0   7.7500      0       3    0      0\n",
       "461  34.0       0.0   8.0500      0       3    1      0\n",
       "733  23.0       0.0  13.0000      0       2    1      0\n",
       "508  28.0       0.0  22.5250      0       3    1      0\n",
       "591  52.0       1.0  78.2667      0       1    0      1\n",
       "\n",
       "[268 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163    0.0\n",
       "2      1.0\n",
       "182    0.0\n",
       "402    0.0\n",
       "800    0.0\n",
       "      ... \n",
       "130    0.0\n",
       "653    1.0\n",
       "233    1.0\n",
       "862    1.0\n",
       "744    1.0\n",
       "Name: Survived, Length: 623, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TN   FP'],\n",
       "       ['FN   TP']], dtype='<U7')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[\"TN   FP\"], [\"FN   TP\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  29]\n",
      " [ 31  72]]\n"
     ]
    }
   ],
   "source": [
    "dt_clf = dt_clf.fit(X_train, y_train)\n",
    "dt_prediction = dt_clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, dt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7761, precision: 0.7129, recall: 0.6990, F1: 0.7059, AUC: 0.7616\n"
     ]
    }
   ],
   "source": [
    "# metrics: 업무 수행 결과를 보여주는 계량적 분석\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, dt_prediction)\n",
    "precision = precision_score(y_test, dt_prediction)\n",
    "recall = recall_score(y_test, dt_prediction)\n",
    "f1 = f1_score(y_test, dt_prediction)\n",
    "roc_auc = roc_auc_score(y_test, dt_prediction)\n",
    "print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'\n",
    "      .format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy: 0.8134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target,\n",
    "                                                     test_size=0.3, stratify=y_target)\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print('rf accuracy: {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 8, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.7978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100],\n",
    "    'max_depth':[6, 8, 10, 12],\n",
    "    'min_samples_leaf':[8, 12, 18],\n",
    "    'min_samples_split':[8, 16, 20]\n",
    "}\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.8396\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=8,\n",
    "                                 min_samples_split=8, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "pred = rf_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns)\n",
    "ftr = ftr_importances.sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr, y=ftr.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'random_state':156,\n",
    "          'early_stoppings':100,\n",
    "          'objective':'binary:logistic'\n",
    "         }\n",
    "num_rounds=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.139647\teval-error:0.141791\n",
      "[1]\ttrain-error:0.126806\teval-error:0.149254\n",
      "[2]\ttrain-error:0.131621\teval-error:0.145522\n",
      "[3]\ttrain-error:0.123596\teval-error:0.13806\n",
      "[4]\ttrain-error:0.120385\teval-error:0.134328\n",
      "[5]\ttrain-error:0.11557\teval-error:0.130597\n",
      "[6]\ttrain-error:0.11557\teval-error:0.130597\n",
      "[7]\ttrain-error:0.113965\teval-error:0.130597\n",
      "[8]\ttrain-error:0.107544\teval-error:0.145522\n",
      "[9]\ttrain-error:0.105939\teval-error:0.130597\n",
      "[10]\ttrain-error:0.102729\teval-error:0.141791\n",
      "[11]\ttrain-error:0.097913\teval-error:0.156716\n",
      "[12]\ttrain-error:0.096308\teval-error:0.149254\n",
      "[13]\ttrain-error:0.096308\teval-error:0.152985\n",
      "[14]\ttrain-error:0.094703\teval-error:0.152985\n",
      "[15]\ttrain-error:0.089888\teval-error:0.152985\n",
      "[16]\ttrain-error:0.088283\teval-error:0.149254\n",
      "[17]\ttrain-error:0.086677\teval-error:0.149254\n",
      "[18]\ttrain-error:0.083467\teval-error:0.156716\n",
      "[19]\ttrain-error:0.081862\teval-error:0.152985\n",
      "[20]\ttrain-error:0.077047\teval-error:0.149254\n",
      "[21]\ttrain-error:0.077047\teval-error:0.152985\n",
      "[22]\ttrain-error:0.073836\teval-error:0.152985\n",
      "[23]\ttrain-error:0.072231\teval-error:0.149254\n",
      "[24]\ttrain-error:0.070626\teval-error:0.152985\n",
      "[25]\ttrain-error:0.072231\teval-error:0.149254\n",
      "[26]\ttrain-error:0.072231\teval-error:0.149254\n",
      "[27]\ttrain-error:0.072231\teval-error:0.149254\n",
      "[28]\ttrain-error:0.070626\teval-error:0.152985\n",
      "[29]\ttrain-error:0.072231\teval-error:0.149254\n",
      "[30]\ttrain-error:0.070626\teval-error:0.149254\n",
      "[31]\ttrain-error:0.069021\teval-error:0.152985\n",
      "[32]\ttrain-error:0.070626\teval-error:0.152985\n",
      "[33]\ttrain-error:0.072231\teval-error:0.152985\n",
      "[34]\ttrain-error:0.070626\teval-error:0.149254\n",
      "[35]\ttrain-error:0.067416\teval-error:0.149254\n",
      "[36]\ttrain-error:0.067416\teval-error:0.145522\n",
      "[37]\ttrain-error:0.064205\teval-error:0.145522\n",
      "[38]\ttrain-error:0.064205\teval-error:0.152985\n",
      "[39]\ttrain-error:0.0626\teval-error:0.149254\n",
      "[40]\ttrain-error:0.060995\teval-error:0.152985\n",
      "[41]\ttrain-error:0.05939\teval-error:0.156716\n",
      "[42]\ttrain-error:0.054575\teval-error:0.156716\n",
      "[43]\ttrain-error:0.054575\teval-error:0.156716\n",
      "[44]\ttrain-error:0.05297\teval-error:0.152985\n",
      "[45]\ttrain-error:0.051364\teval-error:0.156716\n",
      "[46]\ttrain-error:0.051364\teval-error:0.152985\n",
      "[47]\ttrain-error:0.051364\teval-error:0.152985\n",
      "[48]\ttrain-error:0.051364\teval-error:0.156716\n",
      "[49]\ttrain-error:0.051364\teval-error:0.160448\n",
      "[50]\ttrain-error:0.051364\teval-error:0.156716\n",
      "[51]\ttrain-error:0.049759\teval-error:0.156716\n",
      "[52]\ttrain-error:0.049759\teval-error:0.160448\n",
      "[53]\ttrain-error:0.046549\teval-error:0.164179\n",
      "[54]\ttrain-error:0.043339\teval-error:0.164179\n",
      "[55]\ttrain-error:0.043339\teval-error:0.164179\n",
      "[56]\ttrain-error:0.043339\teval-error:0.164179\n",
      "[57]\ttrain-error:0.043339\teval-error:0.156716\n",
      "[58]\ttrain-error:0.041734\teval-error:0.160448\n",
      "[59]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[60]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[61]\ttrain-error:0.040128\teval-error:0.171642\n",
      "[62]\ttrain-error:0.041734\teval-error:0.160448\n",
      "[63]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[64]\ttrain-error:0.040128\teval-error:0.16791\n",
      "[65]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[66]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[67]\ttrain-error:0.040128\teval-error:0.164179\n",
      "[68]\ttrain-error:0.038523\teval-error:0.160448\n",
      "[69]\ttrain-error:0.040128\teval-error:0.16791\n",
      "[70]\ttrain-error:0.040128\teval-error:0.16791\n",
      "[71]\ttrain-error:0.038523\teval-error:0.16791\n",
      "[72]\ttrain-error:0.041734\teval-error:0.16791\n",
      "[73]\ttrain-error:0.041734\teval-error:0.16791\n",
      "[74]\ttrain-error:0.038523\teval-error:0.164179\n",
      "[75]\ttrain-error:0.036918\teval-error:0.156716\n",
      "[76]\ttrain-error:0.035313\teval-error:0.156716\n",
      "[77]\ttrain-error:0.036918\teval-error:0.160448\n",
      "[78]\ttrain-error:0.036918\teval-error:0.160448\n",
      "[79]\ttrain-error:0.038523\teval-error:0.156716\n",
      "[80]\ttrain-error:0.033708\teval-error:0.156716\n",
      "[81]\ttrain-error:0.033708\teval-error:0.164179\n",
      "[82]\ttrain-error:0.035313\teval-error:0.164179\n",
      "[83]\ttrain-error:0.033708\teval-error:0.164179\n",
      "[84]\ttrain-error:0.033708\teval-error:0.160448\n",
      "[85]\ttrain-error:0.033708\teval-error:0.164179\n",
      "[86]\ttrain-error:0.032103\teval-error:0.171642\n",
      "[87]\ttrain-error:0.033708\teval-error:0.160448\n",
      "[88]\ttrain-error:0.032103\teval-error:0.16791\n",
      "[89]\ttrain-error:0.032103\teval-error:0.16791\n",
      "[90]\ttrain-error:0.033708\teval-error:0.160448\n",
      "[91]\ttrain-error:0.032103\teval-error:0.160448\n",
      "[92]\ttrain-error:0.033708\teval-error:0.164179\n",
      "[93]\ttrain-error:0.030498\teval-error:0.160448\n",
      "[94]\ttrain-error:0.030498\teval-error:0.164179\n",
      "[95]\ttrain-error:0.028892\teval-error:0.16791\n",
      "[96]\ttrain-error:0.032103\teval-error:0.164179\n",
      "[97]\ttrain-error:0.030498\teval-error:0.164179\n",
      "[98]\ttrain-error:0.030498\teval-error:0.164179\n",
      "[99]\ttrain-error:0.030498\teval-error:0.164179\n",
      "[100]\ttrain-error:0.030498\teval-error:0.164179\n",
      "[101]\ttrain-error:0.030498\teval-error:0.160448\n",
      "[102]\ttrain-error:0.030498\teval-error:0.156716\n",
      "[103]\ttrain-error:0.030498\teval-error:0.160448\n",
      "[104]\ttrain-error:0.028892\teval-error:0.16791\n",
      "[105]\ttrain-error:0.025682\teval-error:0.171642\n",
      "[106]\ttrain-error:0.027287\teval-error:0.16791\n",
      "[107]\ttrain-error:0.027287\teval-error:0.164179\n",
      "[108]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[109]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[110]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[111]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[112]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[113]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[114]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[115]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[116]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[117]\ttrain-error:0.025682\teval-error:0.16791\n",
      "[118]\ttrain-error:0.028892\teval-error:0.16791\n",
      "[119]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[120]\ttrain-error:0.025682\teval-error:0.164179\n",
      "[121]\ttrain-error:0.022472\teval-error:0.160448\n",
      "[122]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[123]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[124]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[125]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[126]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[127]\ttrain-error:0.025682\teval-error:0.160448\n",
      "[128]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[129]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[130]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[131]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[132]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[133]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[134]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[135]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[136]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[137]\ttrain-error:0.022472\teval-error:0.160448\n",
      "[138]\ttrain-error:0.022472\teval-error:0.16791\n",
      "[139]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[140]\ttrain-error:0.022472\teval-error:0.164179\n",
      "[141]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[142]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[143]\ttrain-error:0.022472\teval-error:0.171642\n",
      "[144]\ttrain-error:0.022472\teval-error:0.16791\n",
      "[145]\ttrain-error:0.020867\teval-error:0.16791\n",
      "[146]\ttrain-error:0.020867\teval-error:0.16791\n",
      "[147]\ttrain-error:0.020867\teval-error:0.171642\n",
      "[148]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[149]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[150]\ttrain-error:0.020867\teval-error:0.160448\n",
      "[151]\ttrain-error:0.020867\teval-error:0.160448\n",
      "[152]\ttrain-error:0.022472\teval-error:0.160448\n",
      "[153]\ttrain-error:0.022472\teval-error:0.160448\n",
      "[154]\ttrain-error:0.020867\teval-error:0.156716\n",
      "[155]\ttrain-error:0.020867\teval-error:0.160448\n",
      "[156]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[157]\ttrain-error:0.019262\teval-error:0.152985\n",
      "[158]\ttrain-error:0.020867\teval-error:0.152985\n",
      "[159]\ttrain-error:0.020867\teval-error:0.156716\n",
      "[160]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[161]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[162]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[163]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[164]\ttrain-error:0.020867\teval-error:0.164179\n",
      "[165]\ttrain-error:0.020867\teval-error:0.16791\n",
      "[166]\ttrain-error:0.019262\teval-error:0.164179\n",
      "[167]\ttrain-error:0.020867\teval-error:0.156716\n",
      "[168]\ttrain-error:0.019262\teval-error:0.164179\n",
      "[169]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[170]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[171]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[172]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[173]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[174]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[175]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[176]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[177]\ttrain-error:0.019262\teval-error:0.164179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[179]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[180]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[181]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[182]\ttrain-error:0.019262\teval-error:0.156716\n",
      "[183]\ttrain-error:0.019262\teval-error:0.160448\n",
      "[184]\ttrain-error:0.019262\teval-error:0.164179\n",
      "[185]\ttrain-error:0.017657\teval-error:0.156716\n",
      "[186]\ttrain-error:0.017657\teval-error:0.164179\n",
      "[187]\ttrain-error:0.017657\teval-error:0.160448\n",
      "[188]\ttrain-error:0.017657\teval-error:0.160448\n",
      "[189]\ttrain-error:0.017657\teval-error:0.16791\n",
      "[190]\ttrain-error:0.017657\teval-error:0.160448\n",
      "[191]\ttrain-error:0.016051\teval-error:0.164179\n",
      "[192]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[193]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[194]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[195]\ttrain-error:0.016051\teval-error:0.164179\n",
      "[196]\ttrain-error:0.016051\teval-error:0.160448\n",
      "[197]\ttrain-error:0.017657\teval-error:0.160448\n",
      "[198]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[199]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[200]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[201]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[202]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[203]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[204]\ttrain-error:0.016051\teval-error:0.160448\n",
      "[205]\ttrain-error:0.014446\teval-error:0.149254\n",
      "[206]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[207]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[208]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[209]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[210]\ttrain-error:0.014446\teval-error:0.149254\n",
      "[211]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[212]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[213]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[214]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[215]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[216]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[217]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[218]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[219]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[220]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[221]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[222]\ttrain-error:0.016051\teval-error:0.156716\n",
      "[223]\ttrain-error:0.016051\teval-error:0.152985\n",
      "[224]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[225]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[226]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[227]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[228]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[229]\ttrain-error:0.016051\teval-error:0.160448\n",
      "[230]\ttrain-error:0.016051\teval-error:0.160448\n",
      "[231]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[232]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[233]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[234]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[235]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[236]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[237]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[238]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[239]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[240]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[241]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[242]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[243]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[244]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[245]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[246]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[247]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[248]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[249]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[250]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[251]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[252]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[253]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[254]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[255]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[256]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[257]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[258]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[259]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[260]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[261]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[262]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[263]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[264]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[265]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[266]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[267]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[268]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[269]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[270]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[271]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[272]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[273]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[274]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[275]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[276]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[277]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[278]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[279]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[280]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[281]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[282]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[283]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[284]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[285]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[286]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[287]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[288]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[289]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[290]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[291]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[292]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[293]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[294]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[295]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[296]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[297]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[298]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[299]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[300]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[301]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[302]\ttrain-error:0.014446\teval-error:0.164179\n",
      "[303]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[304]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[305]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[306]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[307]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[308]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[309]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[310]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[311]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[312]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[313]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[314]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[315]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[316]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[317]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[318]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[319]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[320]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[321]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[322]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[323]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[324]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[325]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[326]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[327]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[328]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[329]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[330]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[331]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[332]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[333]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[334]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[335]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[336]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[337]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[338]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[339]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[340]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[341]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[342]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[343]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[344]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[345]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[346]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[347]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[348]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[349]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[350]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[351]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[352]\ttrain-error:0.014446\teval-error:0.156716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[353]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[354]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[355]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[356]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[357]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[358]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[359]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[360]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[361]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[362]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[363]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[364]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[365]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[366]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[367]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[368]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[369]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[370]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[371]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[372]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[373]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[374]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[375]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[376]\ttrain-error:0.014446\teval-error:0.152985\n",
      "[377]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[378]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[379]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[380]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[381]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[382]\ttrain-error:0.014446\teval-error:0.160448\n",
      "[383]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[384]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[385]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[386]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[387]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[388]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[389]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[390]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[391]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[392]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[393]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[394]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[395]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[396]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[397]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[398]\ttrain-error:0.014446\teval-error:0.156716\n",
      "[399]\ttrain-error:0.014446\teval-error:0.156716\n"
     ]
    }
   ],
   "source": [
    "wlist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "xgb_model = xgb.train(params = params, dtrain = dtrain, num_boost_round = num_rounds, evals = wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval(y_test=None, pred=None):     # default값을 None으로 준다. (호출 시 빈칸일 때 None 입력)\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    \n",
    "    print('오차 행렬\\n', confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 10개 표시: [0, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "predict = xgb_model.predict(dtest)\n",
    "pred = [1 if x > 0.5 else 0 for x in predict]\n",
    "print('예측값 10개 표시:', pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      " [[148  17]\n",
      " [ 25  78]]\n",
      "정확도: 0.8433, 정밀도: 0.8211, 재현율: 0.7573, F1: 0.7879, AUC: 0.8271\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71382\tvalidation_1-auc:0.706531\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.778428\tvalidation_1-auc:0.746631\n",
      "[2]\tvalidation_0-auc:0.860345\tvalidation_1-auc:0.841806\n",
      "[3]\tvalidation_0-auc:0.856591\tvalidation_1-auc:0.841012\n",
      "[4]\tvalidation_0-auc:0.857762\tvalidation_1-auc:0.841659\n",
      "[5]\tvalidation_0-auc:0.881478\tvalidation_1-auc:0.877435\n",
      "[6]\tvalidation_0-auc:0.888462\tvalidation_1-auc:0.88835\n",
      "[7]\tvalidation_0-auc:0.885193\tvalidation_1-auc:0.884937\n",
      "[8]\tvalidation_0-auc:0.887187\tvalidation_1-auc:0.886967\n",
      "[9]\tvalidation_0-auc:0.889181\tvalidation_1-auc:0.883466\n",
      "[10]\tvalidation_0-auc:0.896078\tvalidation_1-auc:0.887938\n",
      "[11]\tvalidation_0-auc:0.896313\tvalidation_1-auc:0.891144\n",
      "[12]\tvalidation_0-auc:0.897277\tvalidation_1-auc:0.889144\n",
      "[13]\tvalidation_0-auc:0.89664\tvalidation_1-auc:0.882524\n",
      "[14]\tvalidation_0-auc:0.899255\tvalidation_1-auc:0.886761\n",
      "[15]\tvalidation_0-auc:0.900628\tvalidation_1-auc:0.888585\n",
      "[16]\tvalidation_0-auc:0.902589\tvalidation_1-auc:0.889114\n",
      "[17]\tvalidation_0-auc:0.901619\tvalidation_1-auc:0.88835\n",
      "[18]\tvalidation_0-auc:0.902338\tvalidation_1-auc:0.888938\n",
      "[19]\tvalidation_0-auc:0.903444\tvalidation_1-auc:0.888585\n",
      "[0]\tvalidation_0-auc:0.709412\tvalidation_1-auc:0.737246\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.762868\tvalidation_1-auc:0.754134\n",
      "[2]\tvalidation_0-auc:0.851481\tvalidation_1-auc:0.848191\n",
      "[3]\tvalidation_0-auc:0.842012\tvalidation_1-auc:0.844042\n",
      "[4]\tvalidation_0-auc:0.845357\tvalidation_1-auc:0.843101\n",
      "[5]\tvalidation_0-auc:0.866899\tvalidation_1-auc:0.866167\n",
      "[6]\tvalidation_0-auc:0.876367\tvalidation_1-auc:0.878847\n",
      "[7]\tvalidation_0-auc:0.872924\tvalidation_1-auc:0.876787\n",
      "[8]\tvalidation_0-auc:0.876324\tvalidation_1-auc:0.881318\n",
      "[9]\tvalidation_0-auc:0.878198\tvalidation_1-auc:0.883995\n",
      "[10]\tvalidation_0-auc:0.885923\tvalidation_1-auc:0.890438\n",
      "[11]\tvalidation_0-auc:0.887525\tvalidation_1-auc:0.889615\n",
      "[12]\tvalidation_0-auc:0.887601\tvalidation_1-auc:0.891439\n",
      "[13]\tvalidation_0-auc:0.888015\tvalidation_1-auc:0.890556\n",
      "[14]\tvalidation_0-auc:0.889802\tvalidation_1-auc:0.895381\n",
      "[15]\tvalidation_0-auc:0.890816\tvalidation_1-auc:0.896205\n",
      "[16]\tvalidation_0-auc:0.893414\tvalidation_1-auc:0.894322\n",
      "[17]\tvalidation_0-auc:0.893393\tvalidation_1-auc:0.897617\n",
      "[18]\tvalidation_0-auc:0.894782\tvalidation_1-auc:0.899559\n",
      "[19]\tvalidation_0-auc:0.896487\tvalidation_1-auc:0.899265\n",
      "[0]\tvalidation_0-auc:0.713122\tvalidation_1-auc:0.725537\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.776156\tvalidation_1-auc:0.721742\n",
      "[2]\tvalidation_0-auc:0.85451\tvalidation_1-auc:0.823213\n",
      "[3]\tvalidation_0-auc:0.844834\tvalidation_1-auc:0.819476\n",
      "[4]\tvalidation_0-auc:0.853469\tvalidation_1-auc:0.825154\n",
      "[5]\tvalidation_0-auc:0.873137\tvalidation_1-auc:0.852457\n",
      "[6]\tvalidation_0-auc:0.886986\tvalidation_1-auc:0.872521\n",
      "[7]\tvalidation_0-auc:0.883183\tvalidation_1-auc:0.866814\n",
      "[8]\tvalidation_0-auc:0.885956\tvalidation_1-auc:0.873139\n",
      "[9]\tvalidation_0-auc:0.88552\tvalidation_1-auc:0.869197\n",
      "[10]\tvalidation_0-auc:0.887781\tvalidation_1-auc:0.878347\n",
      "[11]\tvalidation_0-auc:0.890015\tvalidation_1-auc:0.879612\n",
      "[12]\tvalidation_0-auc:0.887808\tvalidation_1-auc:0.874493\n",
      "[13]\tvalidation_0-auc:0.889105\tvalidation_1-auc:0.87361\n",
      "[14]\tvalidation_0-auc:0.891573\tvalidation_1-auc:0.877846\n",
      "[15]\tvalidation_0-auc:0.891333\tvalidation_1-auc:0.878376\n",
      "[16]\tvalidation_0-auc:0.892641\tvalidation_1-auc:0.877082\n",
      "[17]\tvalidation_0-auc:0.891987\tvalidation_1-auc:0.879612\n",
      "[18]\tvalidation_0-auc:0.892826\tvalidation_1-auc:0.880024\n",
      "[19]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.879376\n",
      "[0]\tvalidation_0-auc:0.709238\tvalidation_1-auc:0.715122\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.779289\tvalidation_1-auc:0.760341\n",
      "[2]\tvalidation_0-auc:0.85287\tvalidation_1-auc:0.848044\n",
      "[3]\tvalidation_0-auc:0.844676\tvalidation_1-auc:0.845072\n",
      "[4]\tvalidation_0-auc:0.845428\tvalidation_1-auc:0.842012\n",
      "[5]\tvalidation_0-auc:0.872679\tvalidation_1-auc:0.873992\n",
      "[6]\tvalidation_0-auc:0.878775\tvalidation_1-auc:0.887967\n",
      "[7]\tvalidation_0-auc:0.875627\tvalidation_1-auc:0.884907\n",
      "[8]\tvalidation_0-auc:0.877588\tvalidation_1-auc:0.890615\n",
      "[9]\tvalidation_0-auc:0.88242\tvalidation_1-auc:0.893351\n",
      "[10]\tvalidation_0-auc:0.88916\tvalidation_1-auc:0.894086\n",
      "[11]\tvalidation_0-auc:0.88989\tvalidation_1-auc:0.895911\n",
      "[12]\tvalidation_0-auc:0.891295\tvalidation_1-auc:0.892498\n",
      "[13]\tvalidation_0-auc:0.890271\tvalidation_1-auc:0.887555\n",
      "[14]\tvalidation_0-auc:0.891813\tvalidation_1-auc:0.888114\n",
      "[15]\tvalidation_0-auc:0.893175\tvalidation_1-auc:0.889938\n",
      "[16]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.890527\n",
      "[17]\tvalidation_0-auc:0.895054\tvalidation_1-auc:0.890291\n",
      "[18]\tvalidation_0-auc:0.895447\tvalidation_1-auc:0.890409\n",
      "[19]\tvalidation_0-auc:0.896269\tvalidation_1-auc:0.889173\n",
      "[0]\tvalidation_0-auc:0.713634\tvalidation_1-auc:0.739247\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.765456\tvalidation_1-auc:0.757517\n",
      "[2]\tvalidation_0-auc:0.84758\tvalidation_1-auc:0.859547\n",
      "[3]\tvalidation_0-auc:0.839479\tvalidation_1-auc:0.854545\n",
      "[4]\tvalidation_0-auc:0.84089\tvalidation_1-auc:0.851839\n",
      "[5]\tvalidation_0-auc:0.863505\tvalidation_1-auc:0.878288\n",
      "[6]\tvalidation_0-auc:0.87263\tvalidation_1-auc:0.888026\n",
      "[7]\tvalidation_0-auc:0.869307\tvalidation_1-auc:0.883554\n",
      "[8]\tvalidation_0-auc:0.871933\tvalidation_1-auc:0.887437\n",
      "[9]\tvalidation_0-auc:0.874134\tvalidation_1-auc:0.887526\n",
      "[10]\tvalidation_0-auc:0.87993\tvalidation_1-auc:0.89341\n",
      "[11]\tvalidation_0-auc:0.880366\tvalidation_1-auc:0.891086\n",
      "[12]\tvalidation_0-auc:0.879658\tvalidation_1-auc:0.891027\n",
      "[13]\tvalidation_0-auc:0.880132\tvalidation_1-auc:0.891821\n",
      "[14]\tvalidation_0-auc:0.8815\tvalidation_1-auc:0.893733\n",
      "[15]\tvalidation_0-auc:0.882556\tvalidation_1-auc:0.896146\n",
      "[16]\tvalidation_0-auc:0.884066\tvalidation_1-auc:0.895528\n",
      "[17]\tvalidation_0-auc:0.884981\tvalidation_1-auc:0.898352\n",
      "[18]\tvalidation_0-auc:0.886795\tvalidation_1-auc:0.9\n",
      "[19]\tvalidation_0-auc:0.887438\tvalidation_1-auc:0.900353\n",
      "[0]\tvalidation_0-auc:0.71534\tvalidation_1-auc:0.723183\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.780596\tvalidation_1-auc:0.723389\n",
      "[2]\tvalidation_0-auc:0.851067\tvalidation_1-auc:0.815416\n",
      "[3]\tvalidation_0-auc:0.839898\tvalidation_1-auc:0.817182\n",
      "[4]\tvalidation_0-auc:0.844752\tvalidation_1-auc:0.816858\n",
      "[5]\tvalidation_0-auc:0.866147\tvalidation_1-auc:0.851162\n",
      "[6]\tvalidation_0-auc:0.881194\tvalidation_1-auc:0.872786\n",
      "[7]\tvalidation_0-auc:0.877348\tvalidation_1-auc:0.868903\n",
      "[8]\tvalidation_0-auc:0.879211\tvalidation_1-auc:0.873669\n",
      "[9]\tvalidation_0-auc:0.880726\tvalidation_1-auc:0.869432\n",
      "[10]\tvalidation_0-auc:0.880671\tvalidation_1-auc:0.87561\n",
      "[11]\tvalidation_0-auc:0.88223\tvalidation_1-auc:0.876993\n",
      "[12]\tvalidation_0-auc:0.880088\tvalidation_1-auc:0.876111\n",
      "[13]\tvalidation_0-auc:0.881189\tvalidation_1-auc:0.872521\n",
      "[14]\tvalidation_0-auc:0.88327\tvalidation_1-auc:0.875522\n",
      "[15]\tvalidation_0-auc:0.88302\tvalidation_1-auc:0.876934\n",
      "[16]\tvalidation_0-auc:0.884185\tvalidation_1-auc:0.87717\n",
      "[17]\tvalidation_0-auc:0.883553\tvalidation_1-auc:0.878111\n",
      "[18]\tvalidation_0-auc:0.885063\tvalidation_1-auc:0.880053\n",
      "[19]\tvalidation_0-auc:0.887487\tvalidation_1-auc:0.8812\n",
      "[0]\tvalidation_0-auc:0.716598\tvalidation_1-auc:0.712062\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.803467\tvalidation_1-auc:0.736717\n",
      "[2]\tvalidation_0-auc:0.872221\tvalidation_1-auc:0.821859\n",
      "[3]\tvalidation_0-auc:0.866948\tvalidation_1-auc:0.826743\n",
      "[4]\tvalidation_0-auc:0.87233\tvalidation_1-auc:0.827949\n",
      "[5]\tvalidation_0-auc:0.894161\tvalidation_1-auc:0.875199\n",
      "[6]\tvalidation_0-auc:0.900426\tvalidation_1-auc:0.889379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\tvalidation_0-auc:0.896558\tvalidation_1-auc:0.884378\n",
      "[8]\tvalidation_0-auc:0.89865\tvalidation_1-auc:0.886937\n",
      "[9]\tvalidation_0-auc:0.902164\tvalidation_1-auc:0.884084\n",
      "[10]\tvalidation_0-auc:0.90795\tvalidation_1-auc:0.888614\n",
      "[11]\tvalidation_0-auc:0.908544\tvalidation_1-auc:0.890144\n",
      "[12]\tvalidation_0-auc:0.908947\tvalidation_1-auc:0.884584\n",
      "[13]\tvalidation_0-auc:0.90941\tvalidation_1-auc:0.878405\n",
      "[14]\tvalidation_0-auc:0.911654\tvalidation_1-auc:0.883819\n",
      "[15]\tvalidation_0-auc:0.913224\tvalidation_1-auc:0.886702\n",
      "[16]\tvalidation_0-auc:0.914389\tvalidation_1-auc:0.889879\n",
      "[17]\tvalidation_0-auc:0.913501\tvalidation_1-auc:0.890468\n",
      "[18]\tvalidation_0-auc:0.916634\tvalidation_1-auc:0.890585\n",
      "[19]\tvalidation_0-auc:0.917261\tvalidation_1-auc:0.890056\n",
      "[0]\tvalidation_0-auc:0.710011\tvalidation_1-auc:0.739776\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.771999\tvalidation_1-auc:0.750338\n",
      "[2]\tvalidation_0-auc:0.860748\tvalidation_1-auc:0.832716\n",
      "[3]\tvalidation_0-auc:0.852401\tvalidation_1-auc:0.832009\n",
      "[4]\tvalidation_0-auc:0.861756\tvalidation_1-auc:0.83501\n",
      "[5]\tvalidation_0-auc:0.880176\tvalidation_1-auc:0.86143\n",
      "[6]\tvalidation_0-auc:0.887738\tvalidation_1-auc:0.874551\n",
      "[7]\tvalidation_0-auc:0.884196\tvalidation_1-auc:0.873257\n",
      "[8]\tvalidation_0-auc:0.887705\tvalidation_1-auc:0.878788\n",
      "[9]\tvalidation_0-auc:0.890135\tvalidation_1-auc:0.881171\n",
      "[10]\tvalidation_0-auc:0.896171\tvalidation_1-auc:0.890468\n",
      "[11]\tvalidation_0-auc:0.897206\tvalidation_1-auc:0.888997\n",
      "[12]\tvalidation_0-auc:0.896994\tvalidation_1-auc:0.88985\n",
      "[13]\tvalidation_0-auc:0.897457\tvalidation_1-auc:0.88985\n",
      "[14]\tvalidation_0-auc:0.898982\tvalidation_1-auc:0.893145\n",
      "[15]\tvalidation_0-auc:0.900235\tvalidation_1-auc:0.895911\n",
      "[16]\tvalidation_0-auc:0.903057\tvalidation_1-auc:0.89441\n",
      "[17]\tvalidation_0-auc:0.903123\tvalidation_1-auc:0.898294\n",
      "[18]\tvalidation_0-auc:0.907972\tvalidation_1-auc:0.901\n",
      "[19]\tvalidation_0-auc:0.908887\tvalidation_1-auc:0.900382\n",
      "[0]\tvalidation_0-auc:0.713956\tvalidation_1-auc:0.704766\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.792103\tvalidation_1-auc:0.716976\n",
      "[2]\tvalidation_0-auc:0.869307\tvalidation_1-auc:0.821447\n",
      "[3]\tvalidation_0-auc:0.856297\tvalidation_1-auc:0.816887\n",
      "[4]\tvalidation_0-auc:0.862666\tvalidation_1-auc:0.815799\n",
      "[5]\tvalidation_0-auc:0.880911\tvalidation_1-auc:0.847279\n",
      "[6]\tvalidation_0-auc:0.892308\tvalidation_1-auc:0.870168\n",
      "[7]\tvalidation_0-auc:0.888451\tvalidation_1-auc:0.865578\n",
      "[8]\tvalidation_0-auc:0.89166\tvalidation_1-auc:0.874169\n",
      "[9]\tvalidation_0-auc:0.892259\tvalidation_1-auc:0.864401\n",
      "[10]\tvalidation_0-auc:0.895234\tvalidation_1-auc:0.876699\n",
      "[11]\tvalidation_0-auc:0.897016\tvalidation_1-auc:0.878288\n",
      "[12]\tvalidation_0-auc:0.897925\tvalidation_1-auc:0.876934\n",
      "[13]\tvalidation_0-auc:0.89962\tvalidation_1-auc:0.87464\n",
      "[14]\tvalidation_0-auc:0.901908\tvalidation_1-auc:0.879347\n",
      "[15]\tvalidation_0-auc:0.901418\tvalidation_1-auc:0.880994\n",
      "[16]\tvalidation_0-auc:0.902583\tvalidation_1-auc:0.881406\n",
      "[17]\tvalidation_0-auc:0.902017\tvalidation_1-auc:0.882465\n",
      "[18]\tvalidation_0-auc:0.904218\tvalidation_1-auc:0.885172\n",
      "[19]\tvalidation_0-auc:0.907269\tvalidation_1-auc:0.884319\n",
      "[0]\tvalidation_0-auc:0.709238\tvalidation_1-auc:0.715122\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.789569\tvalidation_1-auc:0.751545\n",
      "[2]\tvalidation_0-auc:0.858645\tvalidation_1-auc:0.849779\n",
      "[3]\tvalidation_0-auc:0.849776\tvalidation_1-auc:0.844131\n",
      "[4]\tvalidation_0-auc:0.852701\tvalidation_1-auc:0.8416\n",
      "[5]\tvalidation_0-auc:0.878378\tvalidation_1-auc:0.87514\n",
      "[6]\tvalidation_0-auc:0.886768\tvalidation_1-auc:0.890909\n",
      "[7]\tvalidation_0-auc:0.883553\tvalidation_1-auc:0.885849\n",
      "[8]\tvalidation_0-auc:0.885068\tvalidation_1-auc:0.891497\n",
      "[9]\tvalidation_0-auc:0.890238\tvalidation_1-auc:0.89188\n",
      "[10]\tvalidation_0-auc:0.896503\tvalidation_1-auc:0.895175\n",
      "[11]\tvalidation_0-auc:0.896727\tvalidation_1-auc:0.893822\n",
      "[12]\tvalidation_0-auc:0.897811\tvalidation_1-auc:0.890733\n",
      "[13]\tvalidation_0-auc:0.897195\tvalidation_1-auc:0.884966\n",
      "[14]\tvalidation_0-auc:0.898285\tvalidation_1-auc:0.890026\n",
      "[15]\tvalidation_0-auc:0.899745\tvalidation_1-auc:0.891262\n",
      "[16]\tvalidation_0-auc:0.902524\tvalidation_1-auc:0.892321\n",
      "[17]\tvalidation_0-auc:0.901712\tvalidation_1-auc:0.892204\n",
      "[18]\tvalidation_0-auc:0.903373\tvalidation_1-auc:0.893174\n",
      "[19]\tvalidation_0-auc:0.903875\tvalidation_1-auc:0.892351\n",
      "[0]\tvalidation_0-auc:0.713634\tvalidation_1-auc:0.739247\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.770817\tvalidation_1-auc:0.757076\n",
      "[2]\tvalidation_0-auc:0.853431\tvalidation_1-auc:0.860312\n",
      "[3]\tvalidation_0-auc:0.845319\tvalidation_1-auc:0.84925\n",
      "[4]\tvalidation_0-auc:0.847743\tvalidation_1-auc:0.847455\n",
      "[5]\tvalidation_0-auc:0.866817\tvalidation_1-auc:0.875257\n",
      "[6]\tvalidation_0-auc:0.875071\tvalidation_1-auc:0.885555\n",
      "[7]\tvalidation_0-auc:0.870985\tvalidation_1-auc:0.881965\n",
      "[8]\tvalidation_0-auc:0.874112\tvalidation_1-auc:0.886908\n",
      "[9]\tvalidation_0-auc:0.877261\tvalidation_1-auc:0.886084\n",
      "[10]\tvalidation_0-auc:0.882633\tvalidation_1-auc:0.892851\n",
      "[11]\tvalidation_0-auc:0.884338\tvalidation_1-auc:0.890615\n",
      "[12]\tvalidation_0-auc:0.884011\tvalidation_1-auc:0.891027\n",
      "[13]\tvalidation_0-auc:0.883134\tvalidation_1-auc:0.889526\n",
      "[14]\tvalidation_0-auc:0.885646\tvalidation_1-auc:0.891703\n",
      "[15]\tvalidation_0-auc:0.886833\tvalidation_1-auc:0.893881\n",
      "[16]\tvalidation_0-auc:0.888364\tvalidation_1-auc:0.893616\n",
      "[17]\tvalidation_0-auc:0.888528\tvalidation_1-auc:0.896264\n",
      "[18]\tvalidation_0-auc:0.891311\tvalidation_1-auc:0.898617\n",
      "[19]\tvalidation_0-auc:0.893022\tvalidation_1-auc:0.896499\n",
      "[0]\tvalidation_0-auc:0.71534\tvalidation_1-auc:0.723183\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.778346\tvalidation_1-auc:0.723301\n",
      "[2]\tvalidation_0-auc:0.848653\tvalidation_1-auc:0.819682\n",
      "[3]\tvalidation_0-auc:0.8387\tvalidation_1-auc:0.821242\n",
      "[4]\tvalidation_0-auc:0.846136\tvalidation_1-auc:0.819064\n",
      "[5]\tvalidation_0-auc:0.866839\tvalidation_1-auc:0.848308\n",
      "[6]\tvalidation_0-auc:0.881761\tvalidation_1-auc:0.871962\n",
      "[7]\tvalidation_0-auc:0.877392\tvalidation_1-auc:0.867137\n",
      "[8]\tvalidation_0-auc:0.88053\tvalidation_1-auc:0.873433\n",
      "[9]\tvalidation_0-auc:0.881423\tvalidation_1-auc:0.868344\n",
      "[10]\tvalidation_0-auc:0.881625\tvalidation_1-auc:0.875169\n",
      "[11]\tvalidation_0-auc:0.884311\tvalidation_1-auc:0.874434\n",
      "[12]\tvalidation_0-auc:0.881968\tvalidation_1-auc:0.872198\n",
      "[13]\tvalidation_0-auc:0.883853\tvalidation_1-auc:0.870315\n",
      "[14]\tvalidation_0-auc:0.886261\tvalidation_1-auc:0.875199\n",
      "[15]\tvalidation_0-auc:0.885923\tvalidation_1-auc:0.87714\n",
      "[16]\tvalidation_0-auc:0.887187\tvalidation_1-auc:0.877552\n",
      "[17]\tvalidation_0-auc:0.886054\tvalidation_1-auc:0.878964\n",
      "[18]\tvalidation_0-auc:0.888228\tvalidation_1-auc:0.878788\n",
      "[19]\tvalidation_0-auc:0.890396\tvalidation_1-auc:0.880847\n",
      "[0]\tvalidation_0-auc:0.75845\tvalidation_1-auc:0.697529\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.867198\tvalidation_1-auc:0.845425\n",
      "[2]\tvalidation_0-auc:0.885084\tvalidation_1-auc:0.887349\n",
      "[3]\tvalidation_0-auc:0.890173\tvalidation_1-auc:0.887055\n",
      "[4]\tvalidation_0-auc:0.893632\tvalidation_1-auc:0.885966\n",
      "[5]\tvalidation_0-auc:0.895948\tvalidation_1-auc:0.891821\n",
      "[6]\tvalidation_0-auc:0.897435\tvalidation_1-auc:0.893263\n",
      "[7]\tvalidation_0-auc:0.897746\tvalidation_1-auc:0.892998\n",
      "[8]\tvalidation_0-auc:0.899015\tvalidation_1-auc:0.892086\n",
      "[9]\tvalidation_0-auc:0.900295\tvalidation_1-auc:0.894734\n",
      "[10]\tvalidation_0-auc:0.901112\tvalidation_1-auc:0.894381\n",
      "[11]\tvalidation_0-auc:0.902872\tvalidation_1-auc:0.895734\n",
      "[12]\tvalidation_0-auc:0.904049\tvalidation_1-auc:0.89441\n",
      "[13]\tvalidation_0-auc:0.90601\tvalidation_1-auc:0.894763\n",
      "[14]\tvalidation_0-auc:0.90662\tvalidation_1-auc:0.894999\n",
      "[15]\tvalidation_0-auc:0.906817\tvalidation_1-auc:0.894204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\tvalidation_0-auc:0.907176\tvalidation_1-auc:0.896617\n",
      "[17]\tvalidation_0-auc:0.908135\tvalidation_1-auc:0.897764\n",
      "[18]\tvalidation_0-auc:0.908609\tvalidation_1-auc:0.895822\n",
      "[19]\tvalidation_0-auc:0.909039\tvalidation_1-auc:0.894763\n",
      "[0]\tvalidation_0-auc:0.76058\tvalidation_1-auc:0.76093\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.86704\tvalidation_1-auc:0.871492\n",
      "[2]\tvalidation_0-auc:0.877136\tvalidation_1-auc:0.885819\n",
      "[3]\tvalidation_0-auc:0.881974\tvalidation_1-auc:0.892527\n",
      "[4]\tvalidation_0-auc:0.882894\tvalidation_1-auc:0.893586\n",
      "[5]\tvalidation_0-auc:0.88309\tvalidation_1-auc:0.89341\n",
      "[6]\tvalidation_0-auc:0.882654\tvalidation_1-auc:0.891439\n",
      "[7]\tvalidation_0-auc:0.881957\tvalidation_1-auc:0.889938\n",
      "[8]\tvalidation_0-auc:0.885291\tvalidation_1-auc:0.888555\n",
      "[9]\tvalidation_0-auc:0.888032\tvalidation_1-auc:0.884613\n",
      "[10]\tvalidation_0-auc:0.888626\tvalidation_1-auc:0.885555\n",
      "[11]\tvalidation_0-auc:0.88917\tvalidation_1-auc:0.884348\n",
      "[12]\tvalidation_0-auc:0.895321\tvalidation_1-auc:0.880936\n",
      "[13]\tvalidation_0-auc:0.895131\tvalidation_1-auc:0.888438\n",
      "[14]\tvalidation_0-auc:0.898203\tvalidation_1-auc:0.89138\n",
      "[15]\tvalidation_0-auc:0.898171\tvalidation_1-auc:0.888379\n",
      "[16]\tvalidation_0-auc:0.8992\tvalidation_1-auc:0.887791\n",
      "[17]\tvalidation_0-auc:0.900007\tvalidation_1-auc:0.889732\n",
      "[18]\tvalidation_0-auc:0.90145\tvalidation_1-auc:0.886437\n",
      "[19]\tvalidation_0-auc:0.901875\tvalidation_1-auc:0.885966\n",
      "[0]\tvalidation_0-auc:0.751814\tvalidation_1-auc:0.708473\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.865613\tvalidation_1-auc:0.840688\n",
      "[2]\tvalidation_0-auc:0.880355\tvalidation_1-auc:0.873051\n",
      "[3]\tvalidation_0-auc:0.879751\tvalidation_1-auc:0.87564\n",
      "[4]\tvalidation_0-auc:0.882622\tvalidation_1-auc:0.878611\n",
      "[5]\tvalidation_0-auc:0.883657\tvalidation_1-auc:0.880906\n",
      "[6]\tvalidation_0-auc:0.883592\tvalidation_1-auc:0.879112\n",
      "[7]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.875199\n",
      "[8]\tvalidation_0-auc:0.8871\tvalidation_1-auc:0.875993\n",
      "[9]\tvalidation_0-auc:0.886926\tvalidation_1-auc:0.876876\n",
      "[10]\tvalidation_0-auc:0.889432\tvalidation_1-auc:0.875758\n",
      "[11]\tvalidation_0-auc:0.890037\tvalidation_1-auc:0.876728\n",
      "[12]\tvalidation_0-auc:0.892456\tvalidation_1-auc:0.875964\n",
      "[13]\tvalidation_0-auc:0.897359\tvalidation_1-auc:0.882583\n",
      "[14]\tvalidation_0-auc:0.897179\tvalidation_1-auc:0.882259\n",
      "[15]\tvalidation_0-auc:0.898323\tvalidation_1-auc:0.878376\n",
      "[16]\tvalidation_0-auc:0.899685\tvalidation_1-auc:0.874993\n",
      "[17]\tvalidation_0-auc:0.900404\tvalidation_1-auc:0.875346\n",
      "[18]\tvalidation_0-auc:0.899712\tvalidation_1-auc:0.876581\n",
      "[19]\tvalidation_0-auc:0.900557\tvalidation_1-auc:0.875964\n",
      "[0]\tvalidation_0-auc:0.750022\tvalidation_1-auc:0.705825\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.864948\tvalidation_1-auc:0.866255\n",
      "[2]\tvalidation_0-auc:0.87847\tvalidation_1-auc:0.886673\n",
      "[3]\tvalidation_0-auc:0.881118\tvalidation_1-auc:0.88476\n",
      "[4]\tvalidation_0-auc:0.880088\tvalidation_1-auc:0.88276\n",
      "[5]\tvalidation_0-auc:0.883096\tvalidation_1-auc:0.883289\n",
      "[6]\tvalidation_0-auc:0.885182\tvalidation_1-auc:0.885172\n",
      "[7]\tvalidation_0-auc:0.885858\tvalidation_1-auc:0.884701\n",
      "[8]\tvalidation_0-auc:0.887841\tvalidation_1-auc:0.885819\n",
      "[9]\tvalidation_0-auc:0.888615\tvalidation_1-auc:0.883554\n",
      "[10]\tvalidation_0-auc:0.889116\tvalidation_1-auc:0.883789\n",
      "[11]\tvalidation_0-auc:0.89154\tvalidation_1-auc:0.886849\n",
      "[12]\tvalidation_0-auc:0.892347\tvalidation_1-auc:0.886614\n",
      "[13]\tvalidation_0-auc:0.89537\tvalidation_1-auc:0.887673\n",
      "[14]\tvalidation_0-auc:0.896057\tvalidation_1-auc:0.885378\n",
      "[15]\tvalidation_0-auc:0.895621\tvalidation_1-auc:0.885378\n",
      "[16]\tvalidation_0-auc:0.896198\tvalidation_1-auc:0.884142\n",
      "[17]\tvalidation_0-auc:0.897152\tvalidation_1-auc:0.88426\n",
      "[18]\tvalidation_0-auc:0.897283\tvalidation_1-auc:0.884495\n",
      "[19]\tvalidation_0-auc:0.897391\tvalidation_1-auc:0.884613\n",
      "[0]\tvalidation_0-auc:0.750125\tvalidation_1-auc:0.763666\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.862301\tvalidation_1-auc:0.870727\n",
      "[2]\tvalidation_0-auc:0.873671\tvalidation_1-auc:0.891851\n",
      "[3]\tvalidation_0-auc:0.874826\tvalidation_1-auc:0.892615\n",
      "[4]\tvalidation_0-auc:0.874978\tvalidation_1-auc:0.890968\n",
      "[5]\tvalidation_0-auc:0.875218\tvalidation_1-auc:0.892204\n",
      "[6]\tvalidation_0-auc:0.874722\tvalidation_1-auc:0.892704\n",
      "[7]\tvalidation_0-auc:0.873654\tvalidation_1-auc:0.891527\n",
      "[8]\tvalidation_0-auc:0.879979\tvalidation_1-auc:0.893998\n",
      "[9]\tvalidation_0-auc:0.88594\tvalidation_1-auc:0.894675\n",
      "[10]\tvalidation_0-auc:0.885825\tvalidation_1-auc:0.89594\n",
      "[11]\tvalidation_0-auc:0.886512\tvalidation_1-auc:0.893645\n",
      "[12]\tvalidation_0-auc:0.888533\tvalidation_1-auc:0.894969\n",
      "[13]\tvalidation_0-auc:0.889797\tvalidation_1-auc:0.896352\n",
      "[14]\tvalidation_0-auc:0.891998\tvalidation_1-auc:0.896234\n",
      "[15]\tvalidation_0-auc:0.892069\tvalidation_1-auc:0.894734\n",
      "[16]\tvalidation_0-auc:0.894117\tvalidation_1-auc:0.893851\n",
      "[17]\tvalidation_0-auc:0.89409\tvalidation_1-auc:0.892851\n",
      "[18]\tvalidation_0-auc:0.894477\tvalidation_1-auc:0.892557\n",
      "[19]\tvalidation_0-auc:0.89518\tvalidation_1-auc:0.892969\n",
      "[0]\tvalidation_0-auc:0.741212\tvalidation_1-auc:0.713063\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.848081\tvalidation_1-auc:0.839865\n",
      "[2]\tvalidation_0-auc:0.867008\tvalidation_1-auc:0.872904\n",
      "[3]\tvalidation_0-auc:0.867983\tvalidation_1-auc:0.875228\n",
      "[4]\tvalidation_0-auc:0.868838\tvalidation_1-auc:0.876964\n",
      "[5]\tvalidation_0-auc:0.868228\tvalidation_1-auc:0.8787\n",
      "[6]\tvalidation_0-auc:0.868065\tvalidation_1-auc:0.87817\n",
      "[7]\tvalidation_0-auc:0.867585\tvalidation_1-auc:0.878023\n",
      "[8]\tvalidation_0-auc:0.871203\tvalidation_1-auc:0.878523\n",
      "[9]\tvalidation_0-auc:0.871192\tvalidation_1-auc:0.878876\n",
      "[10]\tvalidation_0-auc:0.876367\tvalidation_1-auc:0.880906\n",
      "[11]\tvalidation_0-auc:0.877577\tvalidation_1-auc:0.880994\n",
      "[12]\tvalidation_0-auc:0.877414\tvalidation_1-auc:0.878405\n",
      "[13]\tvalidation_0-auc:0.880334\tvalidation_1-auc:0.882936\n",
      "[14]\tvalidation_0-auc:0.88303\tvalidation_1-auc:0.884025\n",
      "[15]\tvalidation_0-auc:0.883875\tvalidation_1-auc:0.881406\n",
      "[16]\tvalidation_0-auc:0.885117\tvalidation_1-auc:0.882348\n",
      "[17]\tvalidation_0-auc:0.885471\tvalidation_1-auc:0.880229\n",
      "[18]\tvalidation_0-auc:0.885749\tvalidation_1-auc:0.880406\n",
      "[19]\tvalidation_0-auc:0.888211\tvalidation_1-auc:0.879582\n",
      "[0]\tvalidation_0-auc:0.76362\tvalidation_1-auc:0.682701\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.8798\tvalidation_1-auc:0.843542\n",
      "[2]\tvalidation_0-auc:0.897947\tvalidation_1-auc:0.879288\n",
      "[3]\tvalidation_0-auc:0.900241\tvalidation_1-auc:0.883054\n",
      "[4]\tvalidation_0-auc:0.902327\tvalidation_1-auc:0.88426\n",
      "[5]\tvalidation_0-auc:0.904327\tvalidation_1-auc:0.887084\n",
      "[6]\tvalidation_0-auc:0.906201\tvalidation_1-auc:0.891056\n",
      "[7]\tvalidation_0-auc:0.906653\tvalidation_1-auc:0.89241\n",
      "[8]\tvalidation_0-auc:0.908119\tvalidation_1-auc:0.89088\n",
      "[9]\tvalidation_0-auc:0.909786\tvalidation_1-auc:0.890821\n",
      "[10]\tvalidation_0-auc:0.913431\tvalidation_1-auc:0.892145\n",
      "[11]\tvalidation_0-auc:0.913823\tvalidation_1-auc:0.894057\n",
      "[12]\tvalidation_0-auc:0.914825\tvalidation_1-auc:0.892733\n",
      "[13]\tvalidation_0-auc:0.916618\tvalidation_1-auc:0.895263\n",
      "[14]\tvalidation_0-auc:0.917936\tvalidation_1-auc:0.893528\n",
      "[15]\tvalidation_0-auc:0.917566\tvalidation_1-auc:0.893469\n",
      "[16]\tvalidation_0-auc:0.918415\tvalidation_1-auc:0.892704\n",
      "[17]\tvalidation_0-auc:0.920017\tvalidation_1-auc:0.893881\n",
      "[18]\tvalidation_0-auc:0.920355\tvalidation_1-auc:0.894469\n",
      "[19]\tvalidation_0-auc:0.921031\tvalidation_1-auc:0.893645\n",
      "[0]\tvalidation_0-auc:0.779774\tvalidation_1-auc:0.763342\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.878127\tvalidation_1-auc:0.854369\n",
      "[2]\tvalidation_0-auc:0.889802\tvalidation_1-auc:0.888909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\tvalidation_0-auc:0.890358\tvalidation_1-auc:0.892939\n",
      "[4]\tvalidation_0-auc:0.891344\tvalidation_1-auc:0.894175\n",
      "[5]\tvalidation_0-auc:0.898416\tvalidation_1-auc:0.896793\n",
      "[6]\tvalidation_0-auc:0.898835\tvalidation_1-auc:0.89544\n",
      "[7]\tvalidation_0-auc:0.901532\tvalidation_1-auc:0.887732\n",
      "[8]\tvalidation_0-auc:0.903755\tvalidation_1-auc:0.886525\n",
      "[9]\tvalidation_0-auc:0.905422\tvalidation_1-auc:0.889644\n",
      "[10]\tvalidation_0-auc:0.905743\tvalidation_1-auc:0.885937\n",
      "[11]\tvalidation_0-auc:0.907138\tvalidation_1-auc:0.887026\n",
      "[12]\tvalidation_0-auc:0.908413\tvalidation_1-auc:0.884966\n",
      "[13]\tvalidation_0-auc:0.912254\tvalidation_1-auc:0.889879\n",
      "[14]\tvalidation_0-auc:0.912003\tvalidation_1-auc:0.888703\n",
      "[15]\tvalidation_0-auc:0.911257\tvalidation_1-auc:0.886643\n",
      "[16]\tvalidation_0-auc:0.912809\tvalidation_1-auc:0.888555\n",
      "[17]\tvalidation_0-auc:0.914607\tvalidation_1-auc:0.888497\n",
      "[18]\tvalidation_0-auc:0.915675\tvalidation_1-auc:0.888085\n",
      "[19]\tvalidation_0-auc:0.916144\tvalidation_1-auc:0.889144\n",
      "[0]\tvalidation_0-auc:0.756696\tvalidation_1-auc:0.719535\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.863385\tvalidation_1-auc:0.846072\n",
      "[2]\tvalidation_0-auc:0.881865\tvalidation_1-auc:0.872963\n",
      "[3]\tvalidation_0-auc:0.881968\tvalidation_1-auc:0.876052\n",
      "[4]\tvalidation_0-auc:0.884649\tvalidation_1-auc:0.877611\n",
      "[5]\tvalidation_0-auc:0.886152\tvalidation_1-auc:0.880583\n",
      "[6]\tvalidation_0-auc:0.887329\tvalidation_1-auc:0.880877\n",
      "[7]\tvalidation_0-auc:0.893932\tvalidation_1-auc:0.875758\n",
      "[8]\tvalidation_0-auc:0.89756\tvalidation_1-auc:0.87717\n",
      "[9]\tvalidation_0-auc:0.896961\tvalidation_1-auc:0.876934\n",
      "[10]\tvalidation_0-auc:0.89762\tvalidation_1-auc:0.878347\n",
      "[11]\tvalidation_0-auc:0.899227\tvalidation_1-auc:0.87767\n",
      "[12]\tvalidation_0-auc:0.900965\tvalidation_1-auc:0.876522\n",
      "[13]\tvalidation_0-auc:0.905569\tvalidation_1-auc:0.878641\n",
      "[14]\tvalidation_0-auc:0.905999\tvalidation_1-auc:0.87764\n",
      "[15]\tvalidation_0-auc:0.906228\tvalidation_1-auc:0.875051\n",
      "[16]\tvalidation_0-auc:0.906174\tvalidation_1-auc:0.873757\n",
      "[17]\tvalidation_0-auc:0.906076\tvalidation_1-auc:0.873286\n",
      "[18]\tvalidation_0-auc:0.907667\tvalidation_1-auc:0.878052\n",
      "[19]\tvalidation_0-auc:0.907863\tvalidation_1-auc:0.87664\n",
      "[0]\tvalidation_0-auc:0.75304\tvalidation_1-auc:0.692821\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.873698\tvalidation_1-auc:0.867844\n",
      "[2]\tvalidation_0-auc:0.885024\tvalidation_1-auc:0.883407\n",
      "[3]\tvalidation_0-auc:0.887046\tvalidation_1-auc:0.879847\n",
      "[4]\tvalidation_0-auc:0.88461\tvalidation_1-auc:0.877729\n",
      "[5]\tvalidation_0-auc:0.889775\tvalidation_1-auc:0.886731\n",
      "[6]\tvalidation_0-auc:0.891317\tvalidation_1-auc:0.890644\n",
      "[7]\tvalidation_0-auc:0.892831\tvalidation_1-auc:0.888791\n",
      "[8]\tvalidation_0-auc:0.892864\tvalidation_1-auc:0.888526\n",
      "[9]\tvalidation_0-auc:0.894177\tvalidation_1-auc:0.885819\n",
      "[10]\tvalidation_0-auc:0.894825\tvalidation_1-auc:0.884319\n",
      "[11]\tvalidation_0-auc:0.897146\tvalidation_1-auc:0.891056\n",
      "[12]\tvalidation_0-auc:0.898263\tvalidation_1-auc:0.888997\n",
      "[13]\tvalidation_0-auc:0.900481\tvalidation_1-auc:0.892027\n",
      "[14]\tvalidation_0-auc:0.901156\tvalidation_1-auc:0.890262\n",
      "[15]\tvalidation_0-auc:0.900895\tvalidation_1-auc:0.88932\n",
      "[16]\tvalidation_0-auc:0.90108\tvalidation_1-auc:0.887379\n",
      "[17]\tvalidation_0-auc:0.901221\tvalidation_1-auc:0.886084\n",
      "[18]\tvalidation_0-auc:0.901418\tvalidation_1-auc:0.885496\n",
      "[19]\tvalidation_0-auc:0.90205\tvalidation_1-auc:0.884878\n",
      "[0]\tvalidation_0-auc:0.752016\tvalidation_1-auc:0.757782\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.863494\tvalidation_1-auc:0.867314\n",
      "[2]\tvalidation_0-auc:0.874875\tvalidation_1-auc:0.890644\n",
      "[3]\tvalidation_0-auc:0.875507\tvalidation_1-auc:0.891586\n",
      "[4]\tvalidation_0-auc:0.876574\tvalidation_1-auc:0.890674\n",
      "[5]\tvalidation_0-auc:0.876771\tvalidation_1-auc:0.890909\n",
      "[6]\tvalidation_0-auc:0.87616\tvalidation_1-auc:0.891527\n",
      "[7]\tvalidation_0-auc:0.875539\tvalidation_1-auc:0.891056\n",
      "[8]\tvalidation_0-auc:0.883897\tvalidation_1-auc:0.891851\n",
      "[9]\tvalidation_0-auc:0.886986\tvalidation_1-auc:0.895587\n",
      "[10]\tvalidation_0-auc:0.88831\tvalidation_1-auc:0.897264\n",
      "[11]\tvalidation_0-auc:0.890772\tvalidation_1-auc:0.894057\n",
      "[12]\tvalidation_0-auc:0.8944\tvalidation_1-auc:0.89444\n",
      "[13]\tvalidation_0-auc:0.896002\tvalidation_1-auc:0.897411\n",
      "[14]\tvalidation_0-auc:0.898171\tvalidation_1-auc:0.895587\n",
      "[15]\tvalidation_0-auc:0.898002\tvalidation_1-auc:0.896175\n",
      "[16]\tvalidation_0-auc:0.898753\tvalidation_1-auc:0.895175\n",
      "[17]\tvalidation_0-auc:0.899783\tvalidation_1-auc:0.89544\n",
      "[18]\tvalidation_0-auc:0.900927\tvalidation_1-auc:0.89491\n",
      "[19]\tvalidation_0-auc:0.902344\tvalidation_1-auc:0.895999\n",
      "[0]\tvalidation_0-auc:0.748638\tvalidation_1-auc:0.710474\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.850141\tvalidation_1-auc:0.838276\n",
      "[2]\tvalidation_0-auc:0.86837\tvalidation_1-auc:0.873904\n",
      "[3]\tvalidation_0-auc:0.867651\tvalidation_1-auc:0.876876\n",
      "[4]\tvalidation_0-auc:0.87038\tvalidation_1-auc:0.874757\n",
      "[5]\tvalidation_0-auc:0.869704\tvalidation_1-auc:0.87817\n",
      "[6]\tvalidation_0-auc:0.869884\tvalidation_1-auc:0.879818\n",
      "[7]\tvalidation_0-auc:0.869416\tvalidation_1-auc:0.878288\n",
      "[8]\tvalidation_0-auc:0.876248\tvalidation_1-auc:0.874846\n",
      "[9]\tvalidation_0-auc:0.876389\tvalidation_1-auc:0.875257\n",
      "[10]\tvalidation_0-auc:0.881102\tvalidation_1-auc:0.879994\n",
      "[11]\tvalidation_0-auc:0.88211\tvalidation_1-auc:0.879406\n",
      "[12]\tvalidation_0-auc:0.881995\tvalidation_1-auc:0.877552\n",
      "[13]\tvalidation_0-auc:0.884398\tvalidation_1-auc:0.879847\n",
      "[14]\tvalidation_0-auc:0.887754\tvalidation_1-auc:0.883848\n",
      "[15]\tvalidation_0-auc:0.888528\tvalidation_1-auc:0.881965\n",
      "[16]\tvalidation_0-auc:0.890282\tvalidation_1-auc:0.880612\n",
      "[17]\tvalidation_0-auc:0.890538\tvalidation_1-auc:0.879788\n",
      "[18]\tvalidation_0-auc:0.891573\tvalidation_1-auc:0.877023\n",
      "[19]\tvalidation_0-auc:0.892575\tvalidation_1-auc:0.877435\n",
      "[0]\tvalidation_0-auc:0.727663\tvalidation_1-auc:0.754751\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.776118\tvalidation_1-auc:0.753545\n",
      "[2]\tvalidation_0-auc:0.850506\tvalidation_1-auc:0.854398\n",
      "[3]\tvalidation_0-auc:0.841418\tvalidation_1-auc:0.850044\n",
      "[4]\tvalidation_0-auc:0.850931\tvalidation_1-auc:0.852162\n",
      "[5]\tvalidation_0-auc:0.874107\tvalidation_1-auc:0.873492\n",
      "[6]\tvalidation_0-auc:0.884937\tvalidation_1-auc:0.886055\n",
      "[7]\tvalidation_0-auc:0.881309\tvalidation_1-auc:0.883936\n",
      "[8]\tvalidation_0-auc:0.884283\tvalidation_1-auc:0.884819\n",
      "[9]\tvalidation_0-auc:0.888571\tvalidation_1-auc:0.883201\n",
      "[10]\tvalidation_0-auc:0.893028\tvalidation_1-auc:0.889821\n",
      "[11]\tvalidation_0-auc:0.893976\tvalidation_1-auc:0.889585\n",
      "[12]\tvalidation_0-auc:0.89744\tvalidation_1-auc:0.889762\n",
      "[13]\tvalidation_0-auc:0.898465\tvalidation_1-auc:0.887526\n",
      "[14]\tvalidation_0-auc:0.89993\tvalidation_1-auc:0.891439\n",
      "[15]\tvalidation_0-auc:0.899919\tvalidation_1-auc:0.88985\n",
      "[16]\tvalidation_0-auc:0.901935\tvalidation_1-auc:0.887496\n",
      "[17]\tvalidation_0-auc:0.900747\tvalidation_1-auc:0.888144\n",
      "[18]\tvalidation_0-auc:0.901379\tvalidation_1-auc:0.887702\n",
      "[19]\tvalidation_0-auc:0.903297\tvalidation_1-auc:0.887938\n",
      "GridSearchCV 최적 파라미터: {'colsample_bytree': 0.5, 'max_depth': 5, 'min_child_weight': 3}\n",
      "ROC AUC: 0.8914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼 파라미터 테스트의 수행 속도를 향상시키기 위해 n_estimators를 20으로 감소\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=20)\n",
    "\n",
    "params = {'max_depth':[5, 7], 'min_child_weight':[1, 3], 'colsample_bytree':[0.5, 0.75]}\n",
    "\n",
    "# 하이퍼 파라미터 테스트의 수행속도를 향상시키기 위해 cv를 지정하지 않음\n",
    "gridcv = GridSearchCV(xgb_clf, param_grid=params)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds=30, eval_metric='auc',\n",
    "           eval_set=[(X_train, y_train), (X_test, y_test)])\n",
    "\n",
    "print('GridSearchCV 최적 파라미터:', gridcv.best_params_)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:,1], average='micro')\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target,\n",
    "                                                     test_size=0.3, stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=5)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144  21]\n",
      " [ 62  41]]\n"
     ]
    }
   ],
   "source": [
    "pred = sgd_clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['TN   FP'],\n",
       "       ['FN   TP']], dtype='<U7')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[\"TN   FP\"], [\"FN   TP\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6903, precision: 0.6613, recall: 0.3981, F1: 0.4970, AUC: 0.6354\n"
     ]
    }
   ],
   "source": [
    "# metrics: 업무 수행 결과를 보여주는 계량적 분석\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred)\n",
    "roc_auc = roc_auc_score(y_test, pred)\n",
    "print('accuracy: {0:.4f}, precision: {1:.4f}, recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'\n",
    "      .format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target,\n",
    "                                                     test_size=0.3, stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.  ,  0.  ,  8.05, ...,  3.  ,  1.  ,  0.  ],\n",
       "       [48.  ,  0.  , 26.55, ...,  1.  ,  1.  ,  0.  ],\n",
       "       [25.  ,  0.  ,  0.  , ...,  3.  ,  1.  ,  0.  ],\n",
       "       ...,\n",
       "       [42.  ,  0.  , 26.  , ...,  2.  ,  0.  ,  1.  ],\n",
       "       [34.  ,  0.  , 21.  , ...,  2.  ,  1.  ,  1.  ],\n",
       "       [19.  ,  0.  ,  8.05, ...,  3.  ,  1.  ,  0.  ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder \n",
    "onehot = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623,)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values.reshape(623,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = onehot.fit(y_train.values.reshape(623,1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = onehot.transform(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(623)])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are n columns in the feature matrix \n",
    "# after One Hot Encoding. \n",
    "X = tf.cast(X_train.values, dtype=tf.float32)\n",
    "  \n",
    "# Since this is a binary classification problem, \n",
    "# Y can take only 2 values. \n",
    "Y = tf.cast(y_train.values, dtype=tf.float32) \n",
    "  \n",
    "# Trainable Variable Weights \n",
    "W = tf.Variable(tf.zeros([7, 2])) \n",
    "  \n",
    "# Trainable Variable Bias \n",
    "b = tf.Variable(tf.zeros([2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=155, shape=(623, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       ...,\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "logits and labels must have the same shape ((623, 2) vs (623,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    845\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    890\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" % (self,\n\u001b[1;32m--> 891\u001b[1;33m                                                                        other))\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (623,) and (623, 2) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m       \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    851\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (623,) and (623, 2) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-5a1034230216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Sigmoid Cross Entropy Cost Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m cost = tf.nn.sigmoid_cross_entropy_with_logits( \n\u001b[1;32m----> 6\u001b[1;33m                     logits = Y_hat, labels = Y) \n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Gradient Descent Optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m       raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\u001b[1;32m--> 167\u001b[1;33m                        (logits.get_shape(), labels.get_shape()))\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;31m# The logistic loss formula from above is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: logits and labels must have the same shape ((623, 2) vs (623,))"
     ]
    }
   ],
   "source": [
    "# Hypothesis \n",
    "Y_hat = tf.nn.sigmoid(tf.add(tf.matmul(X, W), b)) \n",
    "  \n",
    "# Sigmoid Cross Entropy Cost Function \n",
    "cost = tf.nn.sigmoid_cross_entropy_with_logits( \n",
    "                    logits = Y_hat, labels = Y) \n",
    "  \n",
    "# Gradient Descent Optimizer \n",
    "optimizer = tf.train.GradientDescentOptimizer( \n",
    "         learning_rate = alpha).minimize(cost) \n",
    "  \n",
    "# Global Variables Initializer \n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([7, 1], stddev=0.01))\n",
    "b1 = tf.Variable(tf.random_normal([1], stddev=0.01))  # 1차원 행렬!\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([623, 2], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([2], stddev=0.01))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.01) # learning rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.values\n",
    "X = np.float32(X)\n",
    "\n",
    "Y = y_train.values\n",
    "Y = np.float32(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_batch):\n",
    "    X, Y = .train.next_batch(batch_size)\n",
    "    X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        #X에 저장된 이미지 정보를 입력으로 CNN 모델 실행, 분류 결과 hypothesis에 저장\n",
    "        hypothesis = model(X, training=True)  #train이므로 true. 나중에 test 떄는 false\n",
    "\n",
    "        # 로지스틱 회귀식의 오차 계산식 -> cost에 대입, tf에서 자동으로 오차 가장 적게하는 가중치\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=\n",
    "                                                                        hypothesis,\n",
    "                                                                        labels=Y))\n",
    "        grads = tape.gradient(cost, model.variables)  # 가중치 값들을 리턴\n",
    "\n",
    "    optimizer.apply_gradients(zip(grads, model.variables)) # 오차 최소화 되도록 가중치 수정\n",
    "    total_cost += cost\n",
    "    correct_prediction = tf. equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "print('step: {} Loss: {:.4f} accuracy: {:.4f}'.format(step, total_cost/total_batch,\n",
    "                                                      total_accuracy/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):                        # 550번 반복\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)   # hidden layer의 80%만 랜덤으로 사용해 진행\n",
    "\n",
    "        hypothesis = tf.nn.softmax(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "        grads = tape.gradient(cost, [W1, W2, b1, b2])\n",
    "\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W1, W2, b1, b2]), global_step=global_step)\n",
    "\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    print('step: {} Loss: {:.4f} accuracy: {:.4f}'.format(step, total_cost/total_batch,\n",
    "                                                      total_accuracy/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.nn.softmax(tf.matmul(layer1, W1) + b1)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=Y))\n",
    "        grads = tape.gradient(cost, [W1, b1])\n",
    "\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W1, b1]))\n",
    "\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "    print('step: {} Loss: {:.4f} accuracy: {:.4f}'.format(step, total_cost/total_batch,\n",
    "                                                      total_accuracy/total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: nan\n",
      "Iter: 100, Loss: nan\n",
      "Iter: 200, Loss: nan\n",
      "Iter: 300, Loss: nan\n",
      "Iter: 400, Loss: nan\n",
      "Iter: 500, Loss: nan\n",
      "Iter: 600, Loss: nan\n",
      "Iter: 700, Loss: nan\n",
      "Iter: 800, Loss: nan\n",
      "Iter: 900, Loss: nan\n",
      "Iter: 1000, Loss: nan\n",
      "Iter: 1100, Loss: nan\n",
      "Iter: 1200, Loss: nan\n",
      "Iter: 1300, Loss: nan\n",
      "Iter: 1400, Loss: nan\n",
      "Iter: 1500, Loss: nan\n",
      "Iter: 1600, Loss: nan\n",
      "Iter: 1700, Loss: nan\n",
      "Iter: 1800, Loss: nan\n",
      "Iter: 1900, Loss: nan\n",
      "Iter: 2000, Loss: nan\n",
      "Iter: 2100, Loss: nan\n",
      "Iter: 2200, Loss: nan\n",
      "Iter: 2300, Loss: nan\n",
      "Iter: 2400, Loss: nan\n",
      "Iter: 2500, Loss: nan\n",
      "Iter: 2600, Loss: nan\n",
      "Iter: 2700, Loss: nan\n",
      "Iter: 2800, Loss: nan\n",
      "Iter: 2900, Loss: nan\n",
      "Iter: 3000, Loss: nan\n",
      "Iter: 3100, Loss: nan\n",
      "Iter: 3200, Loss: nan\n",
      "Iter: 3300, Loss: nan\n",
      "Iter: 3400, Loss: nan\n",
      "Iter: 3500, Loss: nan\n",
      "Iter: 3600, Loss: nan\n",
      "Iter: 3700, Loss: nan\n",
      "Iter: 3800, Loss: nan\n",
      "Iter: 3900, Loss: nan\n",
      "Iter: 4000, Loss: nan\n",
      "Iter: 4100, Loss: nan\n",
      "Iter: 4200, Loss: nan\n",
      "Iter: 4300, Loss: nan\n",
      "Iter: 4400, Loss: nan\n",
      "Iter: 4500, Loss: nan\n",
      "Iter: 4600, Loss: nan\n",
      "Iter: 4700, Loss: nan\n",
      "Iter: 4800, Loss: nan\n",
      "Iter: 4900, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "for step in range(5000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "        cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1 - hypothesis))\n",
    "        grads = tape.gradient(cost, [W, b])\n",
    "\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W,b]))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print('Iter: {}, Loss: {:.4f}'.format(step, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 256) (256,)\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "b1 = tf.Variable(tf.random_normal([256], stddev=0.01))  # 1차원 행렬!\n",
    "print(W1.shape, b1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal([10], stddev=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(total_batch):                        # 550번 반복\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        layer1 = tf.nn.relu(tf.matmul(X_train, W1) + b1)\n",
    "\n",
    "        layer1 = tf.nn.dropout(layer1, keep_prob=0.8)   # hidden layer의 80%만 랜덤으로 사용해 진행\n",
    "\n",
    "        hypothesis = tf.nn.softmax(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=hypothesis, labels=y_train))\n",
    "        grads = tape.gradient(cost, [W1, W2, b1, b2])\n",
    "\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W1, W2, b1, b2]), global_step=global_step)\n",
    "\n",
    "    is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    print('step: {} Loss: {:.4f} accuracy: {:.4f}'.format(step, cost, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
