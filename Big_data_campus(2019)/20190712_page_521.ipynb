{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, operator, pandas, glob2\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 함수(날짜와 페이지수를 입력받아 그날짜의 그 페이지수만큼 크롤링 해옴)\n",
    "def crawlingData(date, pageCount):\n",
    "    # 현재 시각을 now라는 변수에 저장\n",
    "    now = datetime.now()\n",
    "    l = [] # 리스트 l\n",
    "\n",
    "    # pagecount는 1페이지부터 사용자가 입력한 페이지 수까지 됨\n",
    "    for pagecount in range(1, int(pageCount)+1):\n",
    "\n",
    "        # 동적으로, 사용자가 입력한 날짜와 뉴스 페이지에 접속\n",
    "        r = requests.get(\"http://news.naver.com/main/list.nhn?mode=LSD&mid=sec&sid1=100&date=\" + str(date) + \"&page=\" + str(pagecount))\n",
    "        c = r.content\n",
    "        soup = BeautifulSoup(c, \"html.parser\")\n",
    "        all = soup.find_all(\"li\")\n",
    "\n",
    "        for item in all:\n",
    "            for item2 in item.find_all(\"dl\"):\n",
    "                d = {} # 사전 d\n",
    "                try:\n",
    "                    linkTag = item2.find(\"dt\", {\"class\": \"\"}).find(\"a\")\n",
    "                    d[\"LinkSrc\"] = linkTag['href'] # 사전 d의 LinkSrc라는 키에 href 내용을 가져와 저장\n",
    "                    title = linkTag.text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\",\", \"\").replace('\"',\"\").replace(\"\\r\", \"\")\n",
    "                    title = title [1:len(title.text) + 1]\n",
    "                    d[\"Title\"] = title\n",
    "                except:\n",
    "                    d[\"LinkSrc\"] = \"None\"\n",
    "                    d[\"Title\"] = \"None\"\n",
    "\n",
    "                try:\n",
    "                    contentTag = item2.find(\"dd\")\n",
    "                    d[\"Content\"] = \\\n",
    "                    contentTag.text.replace(\"\\t\", \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\",\", \"\").replace('\"',\"\").split(\"…\")[0]\n",
    "                    d[\"Company\"] = contentTag.find(\"span\", {\"class\": \"writing\"}).text\n",
    "                    d[\"Date\"] = contentTag.find(\"span\", {\"class\": \"date\"}).text\n",
    "                    #print(d[\"Content\"])\n",
    "                except:\n",
    "                    d[\"Content\"] = \"None\"\n",
    "                    d[\"Company\"] = \"None\"\n",
    "                    d[\"Date\"] = \"None\"\n",
    "\n",
    "                try:\n",
    "                    imgTag = item2.find(\"dt\", {\"class\": \"photo\"}).find(\"img\")\n",
    "                    d[\"imgSrc\"] = imgTag[\"src\"]\n",
    "                except:\n",
    "                    d[\"imgSrc\"] = \"No image\"\n",
    "\n",
    "                l.append(d) # 리스트에 사전 추가 / 한 행마다 사전에 추가\n",
    "\n",
    "    df = pandas.DataFrame(l) # pandas 사용 l의 데이터프레임화\n",
    "\n",
    "    # now(현재시각)을 이용해 csv 파일로 저장\n",
    "    df.to_csv('%s-%s-%s-%s-%s-%s.csv' % (now.year, now.month, now.day, now.hour, now.minute, now.second),\n",
    "              encoding='utf-8-sig', index=False)\n",
    "    print(\"Success Get DataFIle and Save Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Get DataFIle and Save Data\n"
     ]
    }
   ],
   "source": [
    "crawlingData(20190701, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppt. 523 loadFile 함수\n",
    "\n",
    "def loadFile(fileName):\n",
    "    # checkFileName 함수를 호출, 파일이 존재하는지 확인\n",
    "    outputFileName = checkFileName(fileName)\n",
    "    \n",
    "    if outputFileName is not -1:\n",
    "        df = pd.read_csv(outputFileName)\n",
    "        content = df[\"Content\"]\n",
    "        title = df[\"Title\"]\n",
    "        company = df[\"Company\"]\n",
    "        print(company)\n",
    "        print(\"csv File Load Success\")\n",
    "    else:\n",
    "        print(\"Error csv File\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppt. 524 checkFileName\n",
    "\n",
    "def checkFileName(fileName):\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # 같은 경로에 csv 파일 하나도 없으면 -1 리턴\n",
    "    if len(glob2.glob(\"*.csv\")) == 0:\n",
    "        print(\"No file found in this directory\")\n",
    "        return -1\n",
    "    else:\n",
    "        if fileName == \"all\":   # 사용자가 입력한 값이 all 이라면\n",
    "            result = []\n",
    "            # for문 돌며 모든 csv 파일 가져와 읽은 후 result 리스트에 저장\n",
    "            for i in glob2.glob(\"*.csv\"):\n",
    "                result.append(pd.read_csv(i))\n",
    "            \n",
    "            # 새로 만들 파일 이름 지정\n",
    "            outputFileName = '%s-%s-%s-%s-%s-%s merging.csv' %(\n",
    "                now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "            \n",
    "            # 리스트에 저장한 csv 파일들을 resultDf 변수에 저장\n",
    "            resultDf = pd.concat(result, ignore_index = True)\n",
    "            resultDf.to_csv(outputFileName, encoding='utf-8-sig') # csv 파일 생성\n",
    "            return outputFileName\n",
    "        else:                   # 사용자가 입력한 값이 all이 아니라면\n",
    "            return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ crawling\n",
      "Enter news date : 20000101\n",
      "Enter your pageCount : 30\n",
      "Success Get DataFIle and Save Data\n",
      "$ 20010101\n",
      "command error\n",
      "$ crawling\n",
      "Enter news date : 20010101\n",
      "Enter your pageCount : 30\n",
      "Success Get DataFIle and Save Data\n",
      "$ crawling\n",
      "Enter news date : 20100101\n",
      "Enter your pageCount : 30\n",
      "Success Get DataFIle and Save Data\n",
      "$ 20110101\n",
      "command error\n",
      "$ crawling\n",
      "Enter news date : 20110101\n",
      "Enter your pageCount : 30\n",
      "Success Get DataFIle and Save Data\n",
      "$ exit\n"
     ]
    }
   ],
   "source": [
    "# 메인 세팅 함수, 사용자로부터 값을 입력받아 함수를 호출\n",
    "def mainSetting():\n",
    "    while(1):\n",
    "        kb = input(\"$ \")\n",
    "        if kb == \"exit\":\n",
    "            break\n",
    "        elif kb == \"crawling\":\n",
    "            date = input(\"Enter news date : \")\n",
    "            page = input(\"Enter your pageCount : \")\n",
    "            crawlingData(date, page)\n",
    "        elif kb == \"loadAll\":\n",
    "            loadFile(\"all\")\n",
    "        elif kb == \"load\":\n",
    "            fileName = input(\"Enter your csv file name : \")\n",
    "            loadFile(fileName)\n",
    "        else:\n",
    "            print(\"command error\")\n",
    "\n",
    "\n",
    "mainSetting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ crawling\n",
      "Enter news date : 20190101\n",
      "Enter your pageCount : 1\n",
      "Success Get DataFIle and Save Data\n"
     ]
    }
   ],
   "source": [
    "# while(True)는 반복을 위해 있기 때문에, while과 break를 지워도 (한 번만) 실행된다.\n",
    "def mainSetting():\n",
    "    kb = input(\"$ \")\n",
    "    if kb == \"exit\":\n",
    "        pass\n",
    "    elif kb == \"crawling\":\n",
    "        date = input(\"Enter news date : \")\n",
    "        page = input(\"Enter your pageCount : \")\n",
    "        crawlingData(date, page)\n",
    "    elif kb == \"loadAll\":\n",
    "        loadFile(\"all\")\n",
    "    elif kb == \"load\":\n",
    "        fileName = input(\"Enter your csv file name : \")\n",
    "        loadFile(fileName)\n",
    "    else:\n",
    "        print(\"command error\")\n",
    "\n",
    "\n",
    "mainSetting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkFileName(20190101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\python_edu\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2019-7-12-16-23-36 merging.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkFileName(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      아이뉴스24\n",
      "1      한국경제TV\n",
      "2        노컷뉴스\n",
      "3        서울경제\n",
      "4         YTN\n",
      "5         KBS\n",
      "6      아이뉴스24\n",
      "7         뉴시스\n",
      "8        이데일리\n",
      "9         KBS\n",
      "10        뉴시스\n",
      "11        뉴시스\n",
      "12        뉴시스\n",
      "13        SBS\n",
      "14        YTN\n",
      "15        YTN\n",
      "16        YTN\n",
      "17        YTN\n",
      "18        YTN\n",
      "19        YTN\n",
      "20        YTN\n",
      "21       세계일보\n",
      "22       JTBC\n",
      "23       매일경제\n",
      "24     파이낸셜뉴스\n",
      "25       JTBC\n",
      "26       경향신문\n",
      "27       경향신문\n",
      "28        뉴시스\n",
      "29        KBS\n",
      "        ...  \n",
      "90        KBS\n",
      "91     파이낸셜뉴스\n",
      "92       데일리안\n",
      "93       TV조선\n",
      "94       TV조선\n",
      "95      오마이뉴스\n",
      "96       TV조선\n",
      "97       세계일보\n",
      "98       데일리안\n",
      "99        뉴스1\n",
      "100       뉴스1\n",
      "101       뉴스1\n",
      "102       뉴스1\n",
      "103       뉴스1\n",
      "104       뉴스1\n",
      "105       뉴스1\n",
      "106       뉴스1\n",
      "107       뉴스1\n",
      "108       뉴스1\n",
      "109       뉴스1\n",
      "110       뉴스1\n",
      "111       뉴스1\n",
      "112       뉴스1\n",
      "113       뉴스1\n",
      "114       뉴스1\n",
      "115      데일리안\n",
      "116       뉴시스\n",
      "117      데일리안\n",
      "118      데일리안\n",
      "119       뉴스1\n",
      "Name: Company, Length: 120, dtype: object\n",
      "csv File Load Success\n"
     ]
    }
   ],
   "source": [
    "loadFile(\"2019-7-12-14-9-13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20190101"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 12, 13, 28, 51, 875141)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Can't convert 'int' object to str implicitly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a8b5d335070e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert 'int' object to str implicitly"
     ]
    }
   ],
   "source": [
    "age = input()\n",
    "age + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(age)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://news.naver.com/main/list.nhn?%20mode=LSD&mid=sec&sid1=100\n",
    "https://news.naver.com/main/list.nhn?%20mode=LSD&mid=sec&sid1=100&date=20190701&page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
